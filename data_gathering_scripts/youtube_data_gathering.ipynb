{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Z2CakaR2kie"
   },
   "source": [
    "## Getting YouTube captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook shows how to gather data from YouTube and create a dataframe with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Hkc284JQdTE4"
   },
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hcosg0kaAsx7"
   },
   "outputs": [],
   "source": [
    "api_key = 'API_KEY'\n",
    "# replace by the API key that you generate on Google Developers\n",
    "\n",
    "video_id = 'VIDEO_ID'\n",
    "# replace by the video id which is the part of the URL after 'https://www.youtube.com/watch?v='\n",
    "\n",
    "candidate = 'CANDIDATE_NAME'\n",
    "# replace by the name of the candidate\n",
    "\n",
    "content_type = 'CONTENT_TYPE'\n",
    "#replace by the content typoe of the video (interview, speech etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uY01OaX8Bi72"
   },
   "outputs": [],
   "source": [
    "youtube = build('youtube', 'v3', developerKey= api_key)\n",
    "#create a YouTube Data API v.3 object\n",
    "\n",
    "request = youtube.videos().list(part= \"contentDetails,snippet\", id = video_id)\n",
    "response = request.execute()\n",
    "#make a request to the data of the video and execute it\n",
    "#the resulting response is a dictionary with lots of metadata of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "g3XXrLXXB6-K"
   },
   "outputs": [],
   "source": [
    "channel_id = response['items'][0]['snippet']['channelId']\n",
    "channel_title = response['items'][0]['snippet']['channelTitle']\n",
    "video_id = response['items'][0]['id']\n",
    "video_title = response['items'][0]['snippet']['title']\n",
    "video_description = response['items'][0]['snippet']['description']\n",
    "upload_date = response['items'][0]['snippet']['publishedAt'].replace('T', ' ').replace('Z', '')\n",
    "duration = response['items'][0]['contentDetails']['duration'][2:].replace('M', ':').replace('S', '')\n",
    "# query the response to assign data to corresponding variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1Edn5TB3CSlW"
   },
   "outputs": [],
   "source": [
    "srt = YouTubeTranscriptApi.get_transcript(video_id, languages = ['fr'])\n",
    "# get the captions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "B9mDL2xsdebA"
   },
   "outputs": [],
   "source": [
    "transcript = ''\n",
    "for i in srt:\n",
    "    transcript += i['text']\n",
    "# get just the text from the captions data and concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PYiBLEnAd_85"
   },
   "outputs": [],
   "source": [
    "# transcript = transcript.replace('\\xa0\\n', ' ')\n",
    "# transcript = transcript.replace('\\xa0\\xa0', ' ')\n",
    "# transcript = transcript.replace('\\xa0', ' ')\n",
    "# transcript = transcript.replace('\\n', ' ')\n",
    "# # clean the text if necessary, especially if it's intervening the charachters from which we will be splitting the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "1PFj30D9RKCh"
   },
   "outputs": [],
   "source": [
    "all_interview = transcript.split('- ')\n",
    "# gets a dialog list (assuming new speaker's caption starting with a dash)\n",
    "# this substring can change , the text should be inspected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ACphWxa5DdgL"
   },
   "outputs": [],
   "source": [
    "just_interviewer = []\n",
    "just_candidate = []\n",
    "\n",
    "for i in range(1, len(all_interview),2):\n",
    "    just_interviewer.append(all_interview[i -1])\n",
    "    just_candidate.append(all_interview[i])\n",
    "# split the list into interviewer and candidate speech\n",
    "# this assumes that the interviewer speaks first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "7FEnV7qUo9Jf"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'candidate' : candidate,\n",
    "                 'content_type': content_type,\n",
    "                 'channel_id': channel_id,\n",
    "                 'channel_title': channel_title,\n",
    "                 'video_id' : video_id,\n",
    "                 'video_title': video_title,\n",
    "                 'video_description': video_description,\n",
    "                 'upload_date' : upload_date,\n",
    "                 'duration': duration, \n",
    "                 'interviewer_questions' : just_interviewer, \n",
    "                 'candidate_answers' : just_candidate })\n",
    "#create the dataframe"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "youtube_data_gathering",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
